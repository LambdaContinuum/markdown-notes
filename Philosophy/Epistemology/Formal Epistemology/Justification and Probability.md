Suppose we solve the [[The problem of induction|old]] and [[Grue, The new problem of induction|new]] problems of induction. We have a deeper problem, how do beliefs get justified *in the first place?*

Suppose your doctor says you're the healthiest person ever examined. You being suspicious ask how he knows that. He responds by saying it was revealed in a dream. The doctor ought not believe you are the healthiest person examined, as he surely has no justification to believe it.

It seems that in order to have a justified belief, that belief must itself be based upon a justified belief. Put more generally we have the following principle:

1. A belief can only be justified by another belief.

This principle seems plausible, but it has issues. We can keep asking what justifies a belief. There is an *epistemic regress*.

More precisely stated, the following plausible statements are incompatible:
1. A belief can only be justified by another belief.
2. There can be no circular chains of justification.
3. Any justificatory chains must have finite length.
4. Some beliefs are justified.

Denying each of these statements results in the four main responses to the problem of the epistemic regress: foundationalism, coherentism, infinitism, and justification-skepticism.

*Foundationalism* denies (1). Regress eventually comes to an end with some special *basic* beliefs that are justified by something other than beliefs.

*Coherentism* denies (2) and says roughly there can be circular chains of justification. (We'll give a more precise definition later). 

*Infinitism* denies (3) and says that justificatory chains can have infinite lengths.

*Justification-skepticism* denies (4) and says that none of our beliefs are justified. This only says our beliefs are not justified, not that stronger claim that it's impossible that they're justified.

It follows that all four positions are compatible. One could deny more than one of 1-4, and so, for example be a foundationalist and coherentist, holding that justification flows from special basic beliefs and also holding from circular sets of belief. Or one could be an infinitist and a skeptic, holding that our beliefs would be justified if there were a never-ending chain of justifying beliefs, but as it happens there is not. We won't dwell on these possibilities since we only need to deny one and denying each is problematic so there's little motivation to deny more than one.

# Foundationalism
---
Foundationalism says that a belief can be justified by something other than a justified belief. Call these basic beliefs.

Basic beliefs = Beliefs that are justified, but not by other beliefs.

What could justify basic beliefs? One version of foundationalism takes it that what justifies basic beliefs are *experiences*. Experiences are of course not beliefs or the kind of thing that can be justified or unjustified so they can play the role of justifying basic beliefs.

The key claim here is that experience justifies the belief.  The main argument here is that it stops the epistemic regress in a natural way and the claim seems obviously true. The view seems default until we run into a serious problem.

The problem is that we're fallible. Our senses might be mislead or we might be in a [[Radical Skepticism and Closure|skeptical scenario]]. In these cases our senses are inaccurate. We'll see how this problem applies to naive foundationalism and how the two modifications, [[Kinds of Truths|a priori]] foundationalism and dogmatist foundationalism try and solve the problem.

## Naive foundationalism
No matter what other beliefs you have, if you have a red experience then you're justified in believing the object is red. According to naive foundationalism, justification has the

We can put the principle as follows, where R stands for the type of experience.

*Naive foundationalism*
Whatever other beliefs you have,
if you have an R experience then the belief that the object is R is justified.

This is to say that your justification is independent of your other beliefs.

## Problems for Naive foundationalism
Senses might be misleading. Suppose that some object before you is either red or white, and that you can have either a red or a white experience. Suppose you believe that your senses are *inaccurate*. Suppose you now have a red experience. Should you believe that there is a red object before you? No; it's likely that there is a white object before you. Thus, the naive foundationalist position is refuted.

There are two possible types of experience, looks-red and looks-white, and two possible states of the w|orld, is-red and is-white.

|             | Accurate                 | Inaccurate             |
| ----------- | ------------------------ | ---------------------- |
| Looks-red   | Looks-red and Is-red     | Looks-red and Is-white |
| Looks-white | Looks-white and Is-white | Looks-white and Is-red |

Suppose you believe that there is a fair chance your senses are inaccurate, you shouldn't assign high probability to the accurate possibilities. A reasonable prior probability to assign to each possibility may be something like a probability of 1/4.

It follows that P(Is-red | Looks-red) = P(Is-red) = 1/2. The probability of Is-red is exactly the same as it was before. Assuming justification requires an increase in probability, the experience has not justified the belief. This is incompatible with foundationalism.

This failure is caused by two problems:

Naive foundationalism is more attractive when thinking about an agent who doesn't have background beliefs, but this doesn't fit our probabilistic framework where you always being with some prior probability assignment.

Furthermore, prior probabilities encode relations of justification. If the agent is going to get justification for believing that the object is red, then the prior probabilities need to encode beliefs such as "If I have a red experience then it probably is red."

## *A Priori* foundationalism
A priori foundationalism says we have a priori justification that our senses are accurate. So the basic belief is not "the object is red" like in naive foundationalism; the basic belief is "My senses are probably accurate," and this belief is justified *a priori*.

The prior credences now shift to indicate that being accurate is more likely than inaccurate, so red experience justifies the belief as desired.

## Problem for *a priori* foundationalism
Does the agent really have *a priori* justification that her senses are probably accurate? The Bayesian subjectivist says there is no *a priori* justification beyond the rules of probability, and so they will reject *a priori* foundationalism, whereas inductivists think that agents should have *a priori* credences with particular values so they can accept *a priori* foundationalism.

Say we grant inductivism, the chief problem of inductive probabilities, where do these probabilities come from, is especially severe. The inductive *a priori* foundationalist claims we have justification to believe, based on no evidence, that "my senses are probably accurate". Why should we believe that?

What we want is for justification to be provided by our experiences, even when there is no prior belief that our senses are accurate.

## Dogmatist foundationalism
Dogmatist foundationalists hold that in the right conditions, if it appears that H then you have justification to believe H. This justification exists even if you don't have independent justification to believe your senses are accurate.

*Dogmatist Foundationalism* Given the absence of undermining beliefs such as "My senses are inaccurate,"
if you have an R experience then the belief that the object is R is justified.

The conditional is the same for naive foundationalism, you just have an additional condition that restricts the contexts in which the conditional holds.

## Objections to dogmatist foundationlism
It violates conditionalization (see book for example).

According to dogmatism, before the experience the agent doesn't have a justified belief that her beliefs are accurate, but after the experience she does. The experience itself generates justification. This is odd, the agent has apparently justified the belief that her senses are accurate merely by using them. This is called the *bootstrapping argument*. Imagine in practice: "That truck looks red, so I believe it looks red, so my senses are accurate".

According to dogmatism, whatever experience the agent has, it will lead to her increasing her probability that her senses are accurate. The agent can say "I don't have any evidence that my senses are accurate at the moment. But in a moment I will perceive something or other and this will give me justification to believe that they are. Still, I don't believe they are yet." This seems crazy.

A similar objection applies to Max Black's defense of induction. The difference is that Black infers from belief to belief, whereas dogmatist foundationalists infer from experience to belief.

There is a further objection that applies to all versions of foundationalism. The objection is that "nothing can count as a reason for holding a belief except another belief" by Davidson. The idea is that as beliefs are made of concepts, the only things that can justify beliefs are also made of concepts. But experiences are not made of concepts, so they are not in the business of justifying beliefs. So only other beliefs can justify, which lead us to coherentism.

# Coherentism
---
Coherentism says that there are circular chains of justification. More precisely, the coherentist introduces the concept of *coherence*, then argues that a set of beliefs is justified in virtue of the coherence of the beliefs,

What is coherence? The first thing to be said is that *coherence* is a technical concept and philosophers disagree on the best account. But for example, say someone holds to S1, where S1 Is a set of beliefs and someone else holds to S2. Say S1 coheres better than S2. The coherentist will say that someone who holds to S1 is better justified than someone who holds to S2.

Coherence comes in degrees, and likewise justification comes in degrees.

A natural question for the coherentist is how do any beliefs get justified in the first place? The short answer is gradually. Imagine a baby with a set of experiences but no beliefs. As the baby develops, she'll acquire some beliefs but we can suppose that initially none of these beliefs are justified. As the child's mental capacities develop, the set of beliefs grow and we can assume become increasingly coherent. When the beliefs are sufficiently coherent, each belief in the system will be justified. Justification isn't acquired one belief at a time, it spreads slowly across the entire set of beliefs. Light dawns gradually over the whole.

There is intuitive motivation for coherentism. For example, say two witnesses to a crime say he same thing. Even if initially you had no reason to believe that they were telling the truth, the fact that they agree makes it very likely that they are. Or how we have experiences in dreams that are in some ways similar to those in real, but we don't believe our dreams are real, and the reason is that dreams don't cohere.

## First objection to coherentism, Isolation
One object to coherentism is that there can be sets of beliefs that cohere, but which have no connection to the agent's experiences. Coherentism says the beliefs are justified, but it seems clear they are not.

Consider two people, 1 and 2, who have acquired a number of experiences, E, and beliefs, B. Suppose the beliefs are exactly what we would expect people to form given the experiences.

E1 -> B1 and E2 -> B2.

Now suppose we swap the beliefs but keep the experiences the same. We give person 1 the beliefs of person 2 and vice versa, but don't swap experiences.

E1 -> B2 and E2 -> B1.

The only thing relevant to justification is the degree of coherence of the beliefs. As they cohere just as much as before the swap, the coherentist says they remain just as justified. This seems wrong. The problem is that the justification of beliefs has been isolated from experiences.

## Response, Cognitively spontaneous beliefs
TO avoid this problem, the coherentist needs to provide an account of how experiences play a role in justifying beliefs. A detailed theory is offered by Laurence BonJour.

Bonjour introduces the concept of *cognitively spontaneous beliefs*: Cognitively spontaenous beliefs are beliefs which are not inferred from other beliefs, but which strike the agent in a spontaneous, involuntary way.

The key distinction is that cognitively spontaneous beliefs are caused by experiences, but not justified by them

Bonjour argues that an agent can reason her way to a justified belief as follows:
1. I have a cognitively spontaneous belief that H.
2. Cognitively spontaneous beliefs are very likely to be true.
3. Therefore H is very likely to be true.
4. Therefore, probably H.

If this works, experiences play a role in justification, without justifying any beliefs on their own. The experiences get into the picture by causing cognitively spontaneous beliefs, the contents of which are then justified by other beliefs.

But how can the coherentist give an account of how the agent can be justified in believing 1 and 2.

Belief 1 can be divided into two parts, there is the 
1. belief that I believe H and 
2. the belief that the belief in H is cognitively spontaneous.

For (1) to be justified, I must have justified beliefs about what I belief. For (2) to be justified I must have justified beliefs about the nature of my beliefs. Both parts therefore rely on us having second-order justified beliefs about our own first-order belief system. BonJour assumes that we do, calling this Doxastic Presumption. Many philosophers took Doxastic Presumption to be the weak point of the theory.

Justifying belief 2 seems at least as difficult. That cognitively spontaneous beliefs are very likely to be true doesn't seem prima facie plausible. BonJour argues that this can be justified in the same way other beliefs are, empirically, by making observations and learning form experiences. But this seems circular. Bonjour is trying to show that experiences can play a role in justification, even though they don't justify anything themselves. So he can't simply assume that beliefs can be justified by observation and experience.

## Second objection to coherentism: No probability raising
How can beliefs that are individually unjustified manage to acquire justification if they cohere with each other? If one information source is completely unreliable and a second information source is completely unreliable, it seems they must remain just as unreliable even if they agree with each other.

It can be proved that if sources are:
1. probabilistically independent
2. don't increase the probability of a hypothesis alone

then they don't increase the probability of a hypothesis when they agree.

Suppose two witnesses, A and B, report on the color of a table, which can be either red or white, saying either "red" or "white." We can express the probabilistic independence condition (1) as:

*Probabilistic Independence*
P(B says "red" | A says "red" and Red) = P(B says "red | Red)
P(B says "red" | A says "red" and WHITE) = P(B says "red | White)

We can express (2) as:

*Non-foundationalism*
P(Red | A says "red) = P(Red) P(Red | B says "red") = P(Red)

It then follows that A and B agreeing does not confirm the truth of what they say:

*No Coherence Justification*
P(Red | A says "red" and B says "Red") = P(Red)

This seems to refute coherentism, which requires:

*Coherence Justification*
P(Red | A says "red" and B says "red") > P(Red)

This objection seems fatal to coherentism. 

# Infinitism
---
Few philosophers have defended infinitism, but it's prominently defended by Peter Klein. The view is that justificatory chains have infinite length.  What's to be said in favor of infinitism? The motivation comes largely from the problems with foundationalism and coherentism. We'll look at two objections: that we don't have an infinite number of beliefs and even if we do, they are not of the right kind.

## Finite minds
In order for any belief to be justified, agents must have an infinite number of beliefs. But we are only finite creatures. We have a finite number of neurons in our brain and live for a finite length of time, so we cannot have an infinite number of beliefs. Therefore, non of our beliefs are fully justified according to infinitism. Infinitism therefore entails justification skepticism.

## Infinitist responses
The first thing that should be said is that infinitism is compatible with justification-skepticism. Justification can consist in infinite chains of beliefs that we lack and are therefore not justified in believing things.

Of course the point is that we want to avoid justification-skepticism. So let's see if we can justify having infinite beliefs.

Do you believe that 1+1=2? Yes. What about 1 + 3 = 4? You believe all such propositions, of which there are an infinite number, so you do have infinite number of beliefs. Consider your belief that there isn't a dinosaur in the room. You also believe there isn't a rhino, or a chimp...

It becomes plausible you have an infinite number of beliefs. Of course you haven't consciously considered each of these beliefs, but surely you believe lots of things you have never consciously considered.

The idea is something like: If S has a disposition to endorse the conscious thought that H given enough time and encouragement, then S believes H. The infinitist is working with what we might call a *dispositional belief*. This can be contrasted with an *occurent belief*, which is a belief that you are consciously thinking at a particular time. The infitist then argues that it's asking too much of us to hold that beliefs are only justified by occurent beliefs; dispositional justifying beliefs are sufficient.

This seems correct in many cases. For example, when I pick up a textbook I might never have the occurent belief "this book is accurate." Nevertheless, If I'm disposed to believe that the textbook is accurate were I to think about it, then I seem to be justified in believing what I read in the textbook.

Philosophers may object at this point:
1. These dispositional beliefs are not sufficient for justification
2. That we do not have an infinite number of them.

Our probabilistic framework helps assuage these worries.
1. The probability raising theory of justification says that probabilities encode justification relations. Therefore, if according to S's prior probabilities P(H|E) > P(h), then the probability function encodes the belief that E justifies H. So S believes that E justifies H, even if S has never consciously thought about it.
2. It's plausible that S has an infinite number of such dispositional beliefs encoded by the prior credences.

Granting that we have an infinite number of beliefs; this is not sufficient to vindicate infinitism. They need to be the right kind of belief.

## What are the beliefs?
What exactly are these infinite beliefs? When we ask for justification, we seem to arrive at beliefs about appearances before long, and these don't seem to be justified by experiences. One may quickly run out of beliefs to point to that do any justifying. The challenge for the infinitist is to explain how an infinite number of justifying beliefs can get into the story.

## Infinitist response: Infinitism about inference principles
The best infinitist response is that there are an infinite number of *inference principles*, beliefs stating that one belief justifies another.

Start with the following foundationalist structure, where E is an experience (--> represents justification):

E --> H

The infinitist complains that E is not sufficient for justification of H, they also want an inference principle connecting E with H, for example, E justifies H:

E  ------------->
E justifies H --> H

The infinitist now complains that E and "E justifies H" is not sufficient for justifcation of H, they also want an inference principle such as "E and'E justifies H' justify H".

And this repeats ad infinitum. So an infinite number of beliefs are needed for H to be justified.

## Objections to infinitism about inference principles
But this theory doesn't fit with the description of infinitism earlier. There the claim was B1 was justified by B2, which in turn was justified by B3, and so on all the way down. But here the infinite chain of beliefs is not ever-descending vertically, but ever-expanding horizontally. 

This is important because each new chain of beliefs requires justifications, and the infinitist still needs to tell us how. 