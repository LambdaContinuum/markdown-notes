Language of Arithmetic# The Importance of Tarski
---
## *Truth, Models, and Logical Consequence*
Tarski's interest in truth arose from an interest in the expressive power of mathematical theories, including the *definability* of metatheoretically significant notions in them.

For a set $s$ to be definable in $L$ is (roughly) for some formula $F(v)$ of $L$ to be *true* relative to an assignment of members of $s$, and only members of $s$, as referents of $v$.

Thus, *definability* is mathematically tractable only if *truth* is. But is truth tractable? The liar paradox may seem to suggest that it isn't.

Sentence 1: Sentence 1 is not true.

*The Paradox*

P1. 'Sentence 1 is not true' is true iff Sentence 1 is not true.
P2 Sentence 1 = 'Sentence 1 is not true'
C. Sentence 1 is true iff Sentence 1 is not true.

Tarski worried that unless a satisfactory response to the paradox was found, truth couldn't be accepted as a theoretically legitimate notion.

The paradox is generated by:
1. The existence of a self-referential sentence that says of itself that it isn't true
2. The correctness of ⎡'S' is true iff S⎤ which seems to be guaranteed by the very meaning of 'true'.

(2) seems unassailable. As for (1), self-referentiality is clearly allowed in English while self-referentiality in formal languages is guaranteed by the technique of giving every expression, formula, and sentence a numerical code. In such language, one can form "self-referential" sentences that "Say" of themselves that they have a given property P - e.g., of being provable in a given system, in the sense that they are true iff their numerical codes are members of the set that codes P. In short, it isn't self-referentiality that is paradoxical, but self-referentiality *involving truth.*

Tarski's response to the paradox was to abandon the ordinary truth predicates of natural language, which can always be meaningfully applied to sentences containing them, in favor of explicitly defined, but limited, truth predicates that can never be applied.

Let $L$ be an *object language* containing no semantic predicates, and $M$ be a richer *metalanguage* that contains $L$ as a part, plus the means of studying $L$. Tarski showed how to construct a definition in $M$ of a predicate $T$  that applies to all and only the *true sentences of* $L$. Since $T$ is part of $M$ but not $L$, no sentence containing it is one to which it applies, and no liar-sentence is constructible in either $M$ or $L$.

We'll illustrate with a definition of truth for the [[Predicate Logic|first-order]] *language LA of arithmetic*, the quantifiers of which range over the natural numbers, and the nonlogical vocabulary of which consists of the predicate '$=$', the name '$0$', the $1$-place function symbol $'S'$, and the $2$-place function symbols '$+$' and '$\cdot$'.

*Terms of LA*

Any name or variable is a term. If $t_1$ and $t_2$ are terms, so are ⎡$S(t_1)$⎤, ⎡$(t_1 + t_2)$⎤, and ⎡$(t_1 \cdot t_2)$⎤. Nothing else is a term. Call '$0$' and the terms constructed from '$S$' and $'0'$ *numerals*.

*The Referent of a Variable-Free Term t of LA*

If $t$ is '$0$', then $t$ refers to $o$ iff $o$ is the number zero. If $t$ is ⎡$S(t^*)$⎤ for some variable-free term $t^*$, then $t$ refers to $o$ iff $o$ is the successor of the referent of $t^*$.  If $t$ is ⎡$(t_1 + t_2)$⎤ for some variable-free terms $t_1$ and $t_2$, then $t$ refers to $o$ iff $o$ is the sum of the referents of $t_1$ and $t_2$.  If $t$ is ⎡$(t_1 \cdot t_2)$⎤ for some variable-free terms $t_1$ and $t_2$, then $t$ refers to $o$ iff $o$ is the product of the referents of $t_1$ and $t_2$. 

*The Application of a Predicate P of LA*

A predicate $P$ applies to a pair $\langle n, m \rangle$ iff $P$ is '$=$', and $n$ is the same number as $m$.

*Definition of Truth-in-LA*

1.  An atomic sentence ⎡$t_1 = t_2$⎤ is $\text{true}_\text{LA}$ iff '$=$' applies to the pair $\langle n, m \rangle$ that $t_1$ and $t_2$ refer to.
2. ⎡$\neg Q$⎤ is $\text{true}_\text{LA}$ iff $Q$ is not $\text{true}_\text{LA}$. ⎡$Q \land R$⎤ is $\text{true}_\text{LA}$ iff $Q$ and $R$ are both $\text{true}_\text{LA}$. Similar clauses given for ⎡$Q \lor R$⎤, ⎡$Q \to R$⎤, and ⎡$Q \iff R$⎤.
3. ⎡$\exists v Q$⎤ is $\text{true}_\text{LA}$ iff there is a number $n$ designated by a numeral $\underline{n}$, such that the sentence $Q(\underline{n})$ is true.   ⎡$\forall v Q$⎤ is $\text{true}_\text{LA}$ iff for every number $n$ designated by a numeral $\underline{n}$, such that the sentence $Q(\underline{n})$ is true.  $Q(\underline{n})$ is a sentence that arises from the quantified sentence by erasing the quantifier and replacing all free occurrences of $v$ in $Q$ with occurrences of $\underline{n}$.

Tarski required that for each sentence $S$ of LA, an instance of schema T can be derived from the definition of truth-in-LA. Instances arise by replacing '$S^*$' with a name of $S$, and replacing '$P$' by a sentence of $M$ that paraphrases $S$.

*Tarski's Schema T:* $S^*$ is $\text{true}_\text{LA}$ iff $P$.

Since we are antecedently justified in accepting every instance of 'If $S^*$ means that P, then $S^*$ is true iff $P$', we know that for every sentence $S$ of LA, $S$ is *true-in-LA* iff $S$ is *true*. Hence, Tarski's defined predicate is coextensive, over LA, with our ordinary truth predicate.

The truth definition is recursive. Truth is defined for the simplest sentences. Then, the truth of complex sentences is defined in terms of the truth of simpler ones. This works because for each object that LA is used to talk about, there is a variable-free term in LA that designates it. For many languages this is not so. For them, Tarski needs more powerful definitions in which variables are allowed to function as temporary names. This doesn't provide many difficulties. The result is a definition of truth rich enough to satisfy Tarski's metamathematical interests.

His proof of the arithmetical indefinability of arithmetical truth is a good example of those interests. The theorem states that there is no formula of LA that is *true* of the set of numbers that code truths of LA.

His proof of the arithmetical indefinability of arithmetical truth is a good example of those interests. The theorem states that there is no formula of LA that is *true* of the set of numbers that code truths of LA. It can be shown that there is a formula ⎡$\exists y (\text{Self-Application } y, x)$⎤ of LA that is true of $n, m$ iff $m$ is the code of formula $F$ in which a single variable v occurs free, and $n$ is the code of the sentence that results from replacing all free occurrences of $v$ in F with the numeral denoting the code of F. (The self-application of F predicates F of its own code).  Now suppose that there is a formula $T(y)$ of LA that is true of $n$ iff $n$ is the code of a truth. It will then follow that there is a formula H, ⎡$\exists y (\text{Self-Application } y, x \land \neg T(y))$, that is true of $m$ iff $m$ is the code of a formula that isn't true of its own code. Let $h^*$ be the numeral that denotes H's code. Then ⎡$\exists y (\text{Self-Application } y, h^* \land \neg T(y))$⎤ "says" (relative to the coding) that a self-application of $H$ isn't true. Since this sentence is the self-application of H, it "says" of itself that it isn't true. So LA Contains a sentence that is true iff it isn't true. Since this is a contradiction the supposition that led to this result, that there is a formula of LA that is true of $n$ iff $n$ is the code of a truth of LA is false. Arithmetical truth is thus arithmetically indefinable.

Next, note for any axiomatizable proof procedure for LA, there is a formula, $\text{Proof } x, y$, of LA that is true of $n, m$ iff $n$ is the number coding a proof the last line of which is coded by $m$. ⎡$\exists x \text{Proof } x, y$⎤ is true of $m$ iff $m$ is the number of a provable sentence. Since the provable sentences are definable in LA but the truths aren't, the arithmetical truths are not the provable sentences. So if the axioms are true, and the inference rules preserve truth, then some truths aren't provable. This is an elementary form of Godel's first incompleteness result.

These results illustrate Tarski's interest in truth, and the work to which he put his formal notion. The fruitfulness of his definition is further illustrated by the role it plays in his "semantic" definitions of logical truth and consequence. $S$ is *logically true* iff $S$ is true no matter what non-empty domain of quantification is chosen, or what denotations from the domain are given to the non-logical symbols of $S$. $C$ is a logical consequence of a set $P$ of sentences iff every choice of a non-empty domain, plus denotations of the non-logical symbols, that makes the sentences of $P$ true also makes $C$ true. Let a *model* be any choice of a non-empty domain $D$ plus an assignment of denotations from $D$ to non-logical symbols. Names are assigned members of $D$, n-ary predicates are assigned sets of n-tuples of elements of $D$, and n-ary function symbols $f$ are assigned n-place functions $f$ from n-tuples of members of $D$ into $D$. The denotation of a term ⎡$f(t_1, ..., t_n)$⎤ relative to an assignment $A$ of objects in $D$ to variables is defined to be the object that $f$ assigns to the n-tuple of denotations of $t_1, ..., t_n$ relative to $A$.

The definition of *truth in a model* is then abstracted from Tarski's definition of truth.

A *logical truth* is a sentence that is true in all models, and a *logical consequence* of a set P of sentences is a sentence that is true in every model in which all members of P are true. These definitions capture what most logicians and mathematicians take logical truth and consequence to be, and so are good candidates for philosophical analyses of these notions, which is how they're usually treated.

## *The Significance of Tarski for the Philosophy of Language*
The significance of Tarski's work on truth for the study of meaning isn't clear. His goal wasn't to use our antecedently understood notion of truth to *endow* the sentences of previously uninterpreted systems with truth conditions, and hence meaning. It was to *define* restricted truth predicates for already meaning, and antecedently understood, formal languages.

To this end he offered fully explicit definitions, thereby rendering the defined truth predicate *eliminable, without loss of content.* He requires his definitions to be *free of undefined semantic notions* such as reference and application, to be constructible from notions already expressible in the object-language L (plus set theory and syntax for L), and to entail an instance of schema T for each sentence of L.

Since the definition appeals only to set theory and syntax, one who knows those could come to know that is expressed by some sentence, *without knowing anything about its meaning*. Thus, statements of Tarski's truth conditions provide no information about the meanings of sentences. So, if semantics studies meaning, Tarski-truth isn't a semantic notion.

This shows that our ordinary predicate 'is true' differs in meaning from Tarski's formally defined substitute '$T_L$' even though the two are provably coextensive, over L.

This is brought out by the following:

2a. If 'S' means in L that P, then 'S' is a true sentence of L iff P.
2b. If 'S' means in L that P, then 'S' is $T_L$ iff P.
2c. If '$T_L$' is a truth predicate for L, then if 'S' means in L that P, then 'S' IS $T_L$ iff P.

The connection between meaning and truth in reflected in the obviousness of 2a. If prior to learning the meaning of S, we are told that S is true in L iff two times two is four, we can immediately conclude that S doesn't mean in L that two times two isn't four. Since if it did, we would have both that S is true iff two times two is four and by 2a that S is true iff two times two isn't four, which is a contradiction. The [[Kinds of Truths|a priori]] availability of 2a for inferences of this sort is what allows statements of truth conditions to provide information about meaning. By contrast instances of 2b aren't obvious. Thus one could know the sentence and the definition of '$T_{LA}$ ' and still not have enough information to conclude that the sentence mentioned doesn't mean that two times two isn't four.

These conclusions are consistent with Tarski, they are inconsistent with his certain remarks in his later philosophical writing. In explaining his truth definition to nonspecialists, he describes instances of schema T, like "Snow is white" is true in English iff snow is white, as "partial definitions" that give the meaning of the ordinary predicate 'true' as applied to particular sentences. Because of this, he took a general definition that entails a "partial definition" for each sentence of L to be one that *captures the meaning* of our ordinary truth predicate (restricted to L). Since he took his definition to be successful, he thought that his defined truth predicate could play all legitimate theoretical roles for which we need a notion of truth for L. Since our ordinary notion of truth *is* central to semantics, it is therefore not surprising that he should wrong say that his notion of truth can be used to define the central concepts of the theory of meaning.

# Rudolf Carnap's Embrace of Truth-Theoretic Semantics
---
This error is already present in Carnap. Carnap's main point, that truth and confirmation must be sharply distinguished, was a much needed corrective to prevailing views among leading logical empiricists. However, his argument for this correct conclusion suffered from the mistaken idea that corresponding instances of the schemata in (3) as well as (4) have essentially the same content.

3. S / 'S' is true (in L) / 'S' is $T_L$ ('$T_L$' is Tarski's truth predicate.)
4. John knows that S / John knows that 'S' is true (in L) / John knows that 'S' is $T_L$.

They do not. Accept for the sake of argument his idea that necessarily, analytically, and a priori equivalent sentences have the same content. Then, since S and ⎡'S' is $T_L$⎤ are so equivalent, their contents can be identified, as can the contents of ⎡John knows that S⎤ and ⎡John knows that 'S' is $T_L$⎤. However, this is not true of S and ⎡'S' is true (in L)⎤, or of ⎡John knows that S⎤ and ⎡John knows that 'S' is true (in L)⎤. For example, if John doesn't understand English, he may know that the earth is round without knowing that "the earth is round" is a true sentence (of English). Thus, one who takes knowledge of truth conditions to provide such information must be careful to distinguish truth from Tarski-truth.

Carnap fails to do this in his otherwise path-breaking *Introduction to Semantics*. He lays out the idea that a previously uninterpreted language can be given an interpretation by assigning designations to its nonlogical vocabulary, and truth conditions to its sentences, while the meaning of the sentences of an already meaningful language can described by identified designations, and specifying truth conditions. Where he goes wrong is in characterizing the Tarski-like rules for designation and truth as *definitions* of these concepts. This error is easily corrected. If our ordinary notions of truth and designation are non-paradoxical and theoretically legitimate, they can be used in Tarski-style rules to state truth and designation conditions that provide genuine information about meanings.

Carnap's semantic theory also delivers claims about analyticity, labeled *logical truth*, and synonym, labeled *logical equivalence*. These ideas are refined and extended in *Meaning and Necessity* where he introduces *state-descriptions*. Though intended as stand ins for possible world-states, they are essentially models in which a complete assignment of truth values to atomic sentences is sufficient for evaluating all object-language sentences. This work contains two main advances.
1. The method of intension and extension, which is contrasted with Frege's "[[The Logical Study of Language|method of sense and reference]]". The *extension* of a singular term at a state description D is its referent at D. The extension of a predicate at D is the set of things it applies to at D. The extension of a sentence at D is its truth value at D. *Intensions* are functions from state descriptions to extensions. They source roughly as the replacement for Fregean senses. The intension of a singular term is called an *individual concept*, the intension of a predicate is called a *property*, and the intension of a sentence is called a *proposition*. Carnap's innovation is to define these notions in terms of truth and designations, and to integrate them into a formal semantic theory that is a theory of truth conditions. The price of this innovation is a coarse-grained conception of properties and propositions in which logically equivalent predicates express the same properties and logically equivalent sentences express the same propositions. Since Carnap identifies necessity with analyticity, this means that necessarily equivalent sentences "say" the same thing. He doesn't want all necessary truths to turn out synonymous. Thus, he introduces the notion *intensional isomorphism*, according to which two compound expressions are intensionally isomorphic iff they are constructed in the same way from constituents with the same intensions. This is his account of synonymy.. The account is subject to certain Fregean objections. He avoids certain problems by introducing *intensional operators*, the extensions of which are functions that assign extensions to the intensions of their arguments. By allowing such operators, Carnap avoids the hierarchy of indirect senses and references, and the relativization of sense and reference to *occurrences* of expressions, which are consequences of Frege's insistence that the reference of the whole must always be a function of the reference of the parts.
2. The semantic treatment given to the modal notions of necessity and possibility which are introduces as intensional operators in his object language. Roughly put, possibility is truth at some possible world-state, and necessity is truth at all such states. Carnap’s formal treatment of these ideas helped lay the groundwork for future work on intensional logic and possible worlds semantics. However, with his conception of necessity as analyticity, and the accompanying picture of state-descriptions as essentially models for interpreting a language that respect meaning postulates governing conceptual relationships among the nonlogical vocabulary, his system is a halfway house in the journey from standard, extensional systems, and their Tarskian models, to richer systems incorporating genuinely possible ways the world could have been, and the accompanying nonlinguistic accounts of necessity and possibility.

# The Semantic Approach of Donald Davidson
---
The Carnapian idea that Tarski-style rules can be used to endow an uninterpreted formal language with meaning, and also to describe the semantic structure of language already in use, was applied to natural language by Davidson.

The chief technical goal of the program was to identify logical forms of English sentences that could be used to derive the truth conditions of those sentences from axioms interpreting their semantically relevant parts.

The chief philosophical goal was to justify the claim that completing this task would yield a theory of meaning.

Davidson held that systematic knowledge of truth and reference could do all the work for which we need a notion of meaning. His strategy was to embrace Quine's rejection analyticity, synonymy, and our ordinary notion of meaning, substituting knowledge of truth and reference whenever there was something genuine to be captured.

Initially, Davidson, like Carnap, wrongly took Tarski-truth to be the notion needed. Davidson thought, understanding any word or sentence is conceptually dependent on understanding every other word and sentence, a radical version of meaning holism.

The key question for the Davidsonian program: How can one justify the claim that theories of truth qualify as theories of meaning?

Davidson originally held that a truth theory for L is a theory of meaning, if knowledge of what it states is sufficient for understanding L. The problem was in showing that his theories satisfied the condition. How can knowledge of a theory be sufficient for understanding meaning, when its theorems give truth conditions only in the weak sense of pairing sentences with materially equivalent claims? If all one knows about S is given <'S' is true iff P>, one can draw the negative conclusion expressed by <S doesn't mean that ~P> but how does one reach a positive conclusion about what S does mean? Initially Davidson thought that compositionality was the answer. In compositional theories, the truth conditions of sentences are derived from axioms interpreting their parts. Thus, accidentally true statements of truth conditions won't be generated without also generating falsehoods. Instead truth theories that are true and composition will derive only those statements <'S' is true iff P> in which P is a close enough paraphrase of S that "nothing essential to the idea of meaning will remain to be captured".

Foster showed him to be wrong. Let $L_S$ be an extensional fragment of Spanish, and T1 be a compositional theory that delivers a *translational T-theorem* <'S' is true in $L_S$ iff P> in which P means the same as S, for each sentence of $L_S$. Form T2 by replacing all axioms of T1 interpreting an expression, or construction, with new axioms stating different, but extensionally equivalent, interpretations. Since T1 is compositional and true, so is T2, despite the fact that all T-theorems of T2 may be nontranslational, like 6.

6. 'El libro es verde' is true in $L_S$ iff the book is green and first-order arithmetic is incomplete.

Since knowledge of these theorems isn't sufficient to understand $L_S$, T2 can't be a theory of meaning, despite satisfying Davidson's constraints. The problem remains even if we adopt constraints strong enough to rule out all but translational truth theories.

Do I care about? No.
